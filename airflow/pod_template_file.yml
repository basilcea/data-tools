podTemplate: |
  apiVersion: v1
  kind: Pod
  metadata:
    name: placeholder-name
    labels:
      tier: airflow
      component: worker
      release: airflow
  spec:
    initContainers:
      
      - name: git-sync-init
        image: registry.k8s.io/git-sync/git-sync:v3.6.9
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 65533
        env:
          - name: GIT_SYNC_USERNAME
            valueFrom:
              secretKeyRef:
                name: "airflow-user-secrets"
                key: GIT_SYNC_USERNAME
          - name: GIT_SYNC_PASSWORD
            valueFrom:
              secretKeyRef:
                name: "airflow-user-secrets"
                key: GIT_SYNC_PASSWORD
          - name: GIT_SYNC_REV
            value: "HEAD"
          - name: GIT_SYNC_BRANCH
            value: "qa"
          - name: GIT_SYNC_REPO
            value: "https://github.com/one-acre-fund/batch-pipelines.git"
          - name: GIT_SYNC_DEPTH
            value: "1"
          - name: GIT_SYNC_ROOT
            value: "/git"
          - name: GIT_SYNC_DEST
            value: "repo"
          - name: GIT_SYNC_ADD_USER
            value: "true"
          - name: GIT_SYNC_WAIT
            value: "60"
          - name: GIT_SYNC_MAX_SYNC_FAILURES
            value: "0"
          - name: GIT_SYNC_ONE_TIME
            value: "true"
        resources: 
            {}
        volumeMounts:
        - name: dags
          mountPath: /git
    containers:
      - envFrom:      
          []
        env:
          - name: AIRFLOW__CORE__EXECUTOR
            value: LocalExecutor      
          # Hard Coded Airflow Envs
          - name: AIRFLOW__CORE__FERNET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: fernet-key
          # For Airflow <2.3, backward compatibility; moved to [database] in 2.3
          - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: connection
          - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: connection
          - name: AIRFLOW_CONN_AIRFLOW_DB
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: connection
          - name: AIRFLOW__WEBSERVER__SECRET_KEY
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: webserver-secret-key      
          # Dynamically created environment variables
          - name: AIRFLOW_VAR_BRANCH
            value: "qa"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__AIRFLOW_VAR_BRANCH
            value: "qa"
          - name: AIRFLOW_VAR_DAGS_REPO
            value: "one-acre-fund/batch-pipelines"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__AIRFLOW_VAR_DAGS_REPO
            value: "one-acre-fund/batch-pipelines"
          - name: AIRFLOW_VAR_AIRBYTE_CONN_ID
            value: "airbyte"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__AIRFLOW_VAR_AIRBYTE_CONN_ID
            value: "airbyte"
          - name: AIRFLOW_VAR_SAVE_TO_FILE
            value: "FALSE"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__AIRFLOW_VAR_SAVE_TO_FILE
            value: "FALSE"
          - name: DBT_ENV_SECRET_SNOWFLAKE_USER
            value: "airbyte"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__DBT_ENV_SECRET_SNOWFLAKE_USER
            value: "airbyte"
          - name: DBT_SNOWFLAKE_ACCOUNT
            value: "oaf-data"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__DBT_SNOWFLAKE_ACCOUNT
            value: "oaf-data"
          - name: DBT_SNOWFLAKE_ROLE
            value: "ETL_WH_ROLE"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__DBT_SNOWFLAKE_ROLE
            value: "ETL_WH_ROLE"
          - name: DBT_SNOWFLAKE_WAREHOUSE
            value: "ETL_WH"
          - name: AIRFLOW__KUBERNETES_ENVIRONMENT_VARIABLES__DBT_SNOWFLAKE_WAREHOUSE
            value: "ETL_WH"
          # Dynamically created secret envs
          - name: AIRFLOW_CONN_AIRBYTE
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: AIRFLOW_CONN_AIRBYTE
          - name: AIRFLOW_CONN_AIRBYTE_API
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: AIRFLOW_CONN_AIRBYTE_API
          - name: AIRFLOW_CONN_AIRBYTE_HTTP_API
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: AIRFLOW_CONN_AIRBYTE_HTTP_API
          - name: AIRFLOW_VAR_GITHUB_ACCESS_TOKEN
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: AIRFLOW_VAR_GITHUB_ACCESS_TOKEN
          - name: SODA_API_KEY
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: SODA_API_KEY
          - name: SODA_API_KEY_SECRET
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: SODA_API_KEY_SECRET
          - name: DBT_ENV_SECRET_SNOWFLAKE_PASSWORD
            valueFrom:
              secretKeyRef:
                name: airflow-user-secrets
                key: DBT_ENV_SECRET_SNOWFLAKE_PASSWORD
          - name: AIRFLOW__KUBERNETES_SECRETS__AIRFLOW_CONN_AIRBYTE
            value: airflow-user-secrets=AIRFLOW_CONN_AIRBYTE
          - name: AIRFLOW__KUBERNETES_SECRETS__AIRFLOW_CONN_AIRBYTE_API
            value: airflow-user-secrets=AIRFLOW_CONN_AIRBYTE_API
          - name: AIRFLOW__KUBERNETES_SECRETS__AIRFLOW_CONN_AIRBYTE_HTTP_API
            value: airflow-user-secrets=AIRFLOW_CONN_AIRBYTE_HTTP_API
          - name: AIRFLOW__KUBERNETES_SECRETS__AIRFLOW_VAR_GITHUB_ACCESS_TOKEN
            value: airflow-user-secrets=AIRFLOW_VAR_GITHUB_ACCESS_TOKEN
          - name: AIRFLOW__KUBERNETES_SECRETS__SODA_API_KEY
            value: airflow-user-secrets=SODA_API_KEY
          - name: AIRFLOW__KUBERNETES_SECRETS__SODA_API_KEY_SECRET
            value: airflow-user-secrets=SODA_API_KEY_SECRET
          - name: AIRFLOW__KUBERNETES_SECRETS__DBT_ENV_SECRET_SNOWFLAKE_PASSWORD
            value: airflow-user-secrets=DBT_ENV_SECRET_SNOWFLAKE_PASSWORD
          
          # Extra env      
        image: apache/airflow:2.7.1
        imagePullPolicy: IfNotPresent
        securityContext: 
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
        name: base
        resources:
          {}
        volumeMounts:
          - mountPath: "/opt/airflow/logs"
            name: logs
          - name: config
            mountPath: "/opt/airflow/airflow.cfg"
            subPath: airflow.cfg
            readOnly: true
          - name: config
            mountPath: "/opt/airflow/config/airflow_local_settings.py"
            subPath: airflow_local_settings.py
            readOnly: true
          - name: dags
            mountPath: /opt/airflow/dags
            readOnly: false
    restartPolicy: Never
    securityContext: 
      runAsUser: 50000
      fsGroup: 0
    nodeSelector:
      {}
    affinity:
      {}
    terminationGracePeriodSeconds: 600
    tolerations:
      []
    topologySpreadConstraints:
      []
    serviceAccountName: airflow-worker
    volumes:
    - name: dags
      emptyDir: {}
    - name: logs
      persistentVolumeClaim:
        claimName: airflow-logs
    - configMap:
        name: airflow-config
      name: config
config:
  core:
    AIRFLOW__KUBERNETES__KUBE_CLIENT_REQUEST_ARGS: '{\"_request_timeout\":60}'
    test_connection: Enabled
    plugins_folder: /opt/airflow/dags/repo/plugins
  kubernetes_executor:
    AIRFLOW__KUBERNETES_EXECUTOR__DELETE_WORKER_PODS: True
images:
  airflow:
    repository: oaftech.azurecr.io/airflow
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "1.0.2"
  migrationsWaitTimeout: 300
logs:
  persistence:
    enabled: true
    size: 40Gi
    storageClassName: oaf-shared
workers:
  persistence:
    size: 40Gi
    storageClassName: oaf-shared
triggerer:
  persistence:
    size: 40Gi
    storageClassName: oaf-shared

  resources: 
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi
scheduler:
  startupProbe:
    timeoutSeconds: 60
    failureThreshold: 15
    periodSeconds: 10
  livenessProbe:
    initialDelaySeconds: 120
    periodSeconds: 20
    timeoutSeconds: 5
    failureThreshold: 6
webserver:
  startupProbe:
    timeoutSeconds: 1
    failureThreshold: 15
    periodSeconds: 10
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
  livenessProbe: 
    initialDelaySeconds: 180
    periodSeconds: 20
    timeoutSeconds: 5 
    failureThreshold: 6
  defaultUser:
    enabled: false
  webserverConfigConfigMapName: webconfigmap
  env:
   - name: DISCOVERY_URL
     value: $(DISCOVERY_URL)
   - name: CLIENT_ID
     value: $(CLIENT_ID)
   - name: CLIENT_SECRET
     value: $(CLIENT_SECRET)
fernetKey: fernet-key
webserverSecretKey: webserver-secret-key
webserverSecretKeySecretName: airflow-user-secrets
fernetKeySecretName: airflow-user-secrets
postgresql:
  enabled: $(ENABLE_POSTGRESQL)
  auth:
    enablePostgresUser: true
    postgresPassword: $(POSTGRES_ADMIN_PASSWORD)
    username: $(POSTGRES_USER)
    password: $(POSTGRES_PASSWORD)
data:
  metadataSecretName: airflow-user-secrets
pgbouncer:
  enabled: true
  # The maximum number of connections to PgBouncer
  maxClientConn: 10
  # The maximum number of server connections to the metadata database from PgBouncer
  metadataPoolSize: 10
  # The maximum number of server connections to the result backend database from PgBouncer
  resultBackendPoolSize: 5
executor: KubernetesExecutor
dags:
  gitSync:
    enabled: true
    repo: $(DAGS_REPO)
    branch: $(AIRFLOW_BRANCH_NAME)
    subPath: 'dags'
    wait: 60
    credentialsSecret: airflow-user-secrets
    knownHosts: $(KNOWN_HOSTS)
elasticsearch:
  enabled: false
  secretName: airflow-user-secrets
env:
- name: "AIRFLOW_VAR_BRANCH"
  value: $(AIRFLOW_BRANCH_NAME)
- name: "AIRFLOW_VAR_DAGS_REPO"
  value: $(PUSH_REPO)
- name: "AIRFLOW_VAR_AIRBYTE_CONN_ID"
  value: airbyte
- name: "AIRFLOW_VAR_SAVE_TO_FILE"
  value: "FALSE"
- name: "DBT_ENV_SECRET_SNOWFLAKE_USER"
  value: $(DBT_SNOWFLAKE_USER)
- name: "DBT_SNOWFLAKE_ACCOUNT"
  value: $(DBT_SNOWFLAKE_ACCOUNT)
- name: "DBT_SNOWFLAKE_ROLE"
  value: $(DBT_SNOWFLAKE_ROLE)
- name: "DBT_SNOWFLAKE_WAREHOUSE"
  value: $(DBT_SNOWFLAKE_WAREHOUSE)

secret:
- envName: "AIRFLOW_CONN_AIRBYTE"
  secretName: airflow-user-secrets
  secretKey: "AIRFLOW_CONN_AIRBYTE"
- envName: "AIRFLOW_CONN_AIRBYTE_API"
  secretName: airflow-user-secrets
  secretKey: "AIRFLOW_CONN_AIRBYTE_API"
- envName: "AIRFLOW_CONN_AIRBYTE_HTTP_API"
  secretName: airflow-user-secrets
  secretKey: "AIRFLOW_CONN_AIRBYTE_HTTP_API"
- envName: "AIRFLOW_VAR_GITHUB_ACCESS_TOKEN"
  secretName: airflow-user-secrets
  secretKey: "AIRFLOW_VAR_GITHUB_ACCESS_TOKEN"
- envName: "SODA_API_KEY"
  secretName: airflow-user-secrets
  secretKey: "SODA_API_KEY"
- envName: "SODA_API_KEY_SECRET"
  secretName: airflow-user-secrets
  secretKey: "SODA_API_KEY_SECRET"
- envName: "DBT_ENV_SECRET_SNOWFLAKE_PASSWORD"
  secretName: airflow-user-secrets
  secretKey: "DBT_ENV_SECRET_SNOWFLAKE_PASSWORD"

